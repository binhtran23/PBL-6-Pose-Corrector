{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3135, 138)\n",
      "Columns: ['video_id', 'rep_id', 'frame_id', 'lm_0_x', 'lm_0_y', 'lm_0_z', 'lm_0_vis', 'lm_1_x', 'lm_1_y', 'lm_1_z', 'lm_1_vis', 'lm_2_x', 'lm_2_y', 'lm_2_z', 'lm_2_vis', 'lm_3_x', 'lm_3_y', 'lm_3_z', 'lm_3_vis', 'lm_4_x', 'lm_4_y', 'lm_4_z', 'lm_4_vis', 'lm_5_x', 'lm_5_y', 'lm_5_z', 'lm_5_vis', 'lm_6_x', 'lm_6_y', 'lm_6_z', 'lm_6_vis', 'lm_7_x', 'lm_7_y', 'lm_7_z', 'lm_7_vis', 'lm_8_x', 'lm_8_y', 'lm_8_z', 'lm_8_vis', 'lm_9_x', 'lm_9_y', 'lm_9_z', 'lm_9_vis', 'lm_10_x', 'lm_10_y', 'lm_10_z', 'lm_10_vis', 'lm_11_x', 'lm_11_y', 'lm_11_z', 'lm_11_vis', 'lm_12_x', 'lm_12_y', 'lm_12_z', 'lm_12_vis', 'lm_13_x', 'lm_13_y', 'lm_13_z', 'lm_13_vis', 'lm_14_x', 'lm_14_y', 'lm_14_z', 'lm_14_vis', 'lm_15_x', 'lm_15_y', 'lm_15_z', 'lm_15_vis', 'lm_16_x', 'lm_16_y', 'lm_16_z', 'lm_16_vis', 'lm_17_x', 'lm_17_y', 'lm_17_z', 'lm_17_vis', 'lm_18_x', 'lm_18_y', 'lm_18_z', 'lm_18_vis', 'lm_19_x', 'lm_19_y', 'lm_19_z', 'lm_19_vis', 'lm_20_x', 'lm_20_y', 'lm_20_z', 'lm_20_vis', 'lm_21_x', 'lm_21_y', 'lm_21_z', 'lm_21_vis', 'lm_22_x', 'lm_22_y', 'lm_22_z', 'lm_22_vis', 'lm_23_x', 'lm_23_y', 'lm_23_z', 'lm_23_vis', 'lm_24_x', 'lm_24_y', 'lm_24_z', 'lm_24_vis', 'lm_25_x', 'lm_25_y', 'lm_25_z', 'lm_25_vis', 'lm_26_x', 'lm_26_y', 'lm_26_z', 'lm_26_vis', 'lm_27_x', 'lm_27_y', 'lm_27_z', 'lm_27_vis', 'lm_28_x', 'lm_28_y', 'lm_28_z', 'lm_28_vis', 'lm_29_x', 'lm_29_y', 'lm_29_z', 'lm_29_vis', 'lm_30_x', 'lm_30_y', 'lm_30_z', 'lm_30_vis', 'lm_31_x', 'lm_31_y', 'lm_31_z', 'lm_31_vis', 'lm_32_x', 'lm_32_y', 'lm_32_z', 'lm_32_vis', 'label_back', 'label_elbow', 'label_flare']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>rep_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>lm_0_x</th>\n",
       "      <th>lm_0_y</th>\n",
       "      <th>lm_0_z</th>\n",
       "      <th>lm_0_vis</th>\n",
       "      <th>lm_1_x</th>\n",
       "      <th>lm_1_y</th>\n",
       "      <th>lm_1_z</th>\n",
       "      <th>...</th>\n",
       "      <th>lm_31_y</th>\n",
       "      <th>lm_31_z</th>\n",
       "      <th>lm_31_vis</th>\n",
       "      <th>lm_32_x</th>\n",
       "      <th>lm_32_y</th>\n",
       "      <th>lm_32_z</th>\n",
       "      <th>lm_32_vis</th>\n",
       "      <th>label_back</th>\n",
       "      <th>label_elbow</th>\n",
       "      <th>label_flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01502df8-593c-42d0-86ae-7cbd48d8741a</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.483223</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>0.491386</td>\n",
       "      <td>0.156659</td>\n",
       "      <td>-0.073906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924898</td>\n",
       "      <td>-0.376060</td>\n",
       "      <td>0.983876</td>\n",
       "      <td>0.494905</td>\n",
       "      <td>0.822694</td>\n",
       "      <td>0.473240</td>\n",
       "      <td>0.569445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01502df8-593c-42d0-86ae-7cbd48d8741a</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.481026</td>\n",
       "      <td>0.170386</td>\n",
       "      <td>-0.056209</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.489419</td>\n",
       "      <td>0.156550</td>\n",
       "      <td>-0.075012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925647</td>\n",
       "      <td>-0.353399</td>\n",
       "      <td>0.983541</td>\n",
       "      <td>0.495075</td>\n",
       "      <td>0.804442</td>\n",
       "      <td>0.474874</td>\n",
       "      <td>0.557250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01502df8-593c-42d0-86ae-7cbd48d8741a</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.479034</td>\n",
       "      <td>0.170274</td>\n",
       "      <td>-0.056601</td>\n",
       "      <td>0.998789</td>\n",
       "      <td>0.487178</td>\n",
       "      <td>0.156233</td>\n",
       "      <td>-0.075076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926066</td>\n",
       "      <td>-0.349490</td>\n",
       "      <td>0.983468</td>\n",
       "      <td>0.494276</td>\n",
       "      <td>0.820685</td>\n",
       "      <td>0.416490</td>\n",
       "      <td>0.558365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01502df8-593c-42d0-86ae-7cbd48d8741a</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.479740</td>\n",
       "      <td>0.177363</td>\n",
       "      <td>-0.057385</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.486515</td>\n",
       "      <td>0.160765</td>\n",
       "      <td>-0.075857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926393</td>\n",
       "      <td>-0.252694</td>\n",
       "      <td>0.982678</td>\n",
       "      <td>0.485917</td>\n",
       "      <td>0.865583</td>\n",
       "      <td>0.256504</td>\n",
       "      <td>0.566924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01502df8-593c-42d0-86ae-7cbd48d8741a</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.479656</td>\n",
       "      <td>0.188291</td>\n",
       "      <td>-0.033205</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.484254</td>\n",
       "      <td>0.169241</td>\n",
       "      <td>-0.052964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926534</td>\n",
       "      <td>-0.266953</td>\n",
       "      <td>0.982584</td>\n",
       "      <td>0.477057</td>\n",
       "      <td>0.872099</td>\n",
       "      <td>0.260511</td>\n",
       "      <td>0.579873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               video_id  rep_id  frame_id    lm_0_x    lm_0_y  \\\n",
       "0  01502df8-593c-42d0-86ae-7cbd48d8741a       1        35  0.483223  0.170639   \n",
       "1  01502df8-593c-42d0-86ae-7cbd48d8741a       1        36  0.481026  0.170386   \n",
       "2  01502df8-593c-42d0-86ae-7cbd48d8741a       1        37  0.479034  0.170274   \n",
       "3  01502df8-593c-42d0-86ae-7cbd48d8741a       1        38  0.479740  0.177363   \n",
       "4  01502df8-593c-42d0-86ae-7cbd48d8741a       1        39  0.479656  0.188291   \n",
       "\n",
       "     lm_0_z  lm_0_vis    lm_1_x    lm_1_y    lm_1_z  ...   lm_31_y   lm_31_z  \\\n",
       "0 -0.055122  0.998547  0.491386  0.156659 -0.073906  ...  0.924898 -0.376060   \n",
       "1 -0.056209  0.998681  0.489419  0.156550 -0.075012  ...  0.925647 -0.353399   \n",
       "2 -0.056601  0.998789  0.487178  0.156233 -0.075076  ...  0.926066 -0.349490   \n",
       "3 -0.057385  0.998750  0.486515  0.160765 -0.075857  ...  0.926393 -0.252694   \n",
       "4 -0.033205  0.998812  0.484254  0.169241 -0.052964  ...  0.926534 -0.266953   \n",
       "\n",
       "   lm_31_vis   lm_32_x   lm_32_y   lm_32_z  lm_32_vis  label_back  \\\n",
       "0   0.983876  0.494905  0.822694  0.473240   0.569445           0   \n",
       "1   0.983541  0.495075  0.804442  0.474874   0.557250           0   \n",
       "2   0.983468  0.494276  0.820685  0.416490   0.558365           0   \n",
       "3   0.982678  0.485917  0.865583  0.256504   0.566924           0   \n",
       "4   0.982584  0.477057  0.872099  0.260511   0.579873           0   \n",
       "\n",
       "   label_elbow  label_flare  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            0            0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('output/summarry_biceps_curl.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3135, 132)\n",
      "y shape: (3135, 3)\n",
      "\n",
      "Train set: (2451, 132)\n",
      "Test set: (684, 132)\n",
      "Video train: 43\n",
      "Video test: 11\n"
     ]
    }
   ],
   "source": [
    "# 2. Chu·∫©n b·ªã d·ªØ li·ªáu - PER-FRAME (kh√¥ng d√πng sequences)\n",
    "\n",
    "# X√°c ƒë·ªãnh c√°c c·ªôt Feature (132 features: 33 landmarks x 4 gi√° tr·ªã)\n",
    "feature_cols = []\n",
    "for i in range(33):\n",
    "    feature_cols.extend([f'lm_{i}_x', f'lm_{i}_y', f'lm_{i}_z', f'lm_{i}_vis'])\n",
    "\n",
    "# X√°c ƒë·ªãnh c√°c c·ªôt Label (Multi-label classification)\n",
    "label_cols = ['label_back', 'label_elbow', 'label_flare']\n",
    "\n",
    "# Tr√≠ch xu·∫•t X (features) v√† y (labels) cho t·ª´ng frame\n",
    "X = df[feature_cols].values\n",
    "y = df[label_cols].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")  # (s·ªë_frames, 132)\n",
    "print(f\"y shape: {y.shape}\")  # (s·ªë_frames, 3)\n",
    "\n",
    "# Chia t·∫≠p train/test theo video_id ƒë·ªÉ tr√°nh data leakage\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, groups=df['video_id']))\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n",
    "print(f\"Video train: {df.iloc[train_idx]['video_id'].nunique()}\")\n",
    "print(f\"Video test: {df.iloc[test_idx]['video_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫•u h√¨nh m√¥ h√¨nh ƒë√£ s·∫µn s√†ng!\n",
      "S·ªë m√¥ h√¨nh: 3\n"
     ]
    }
   ],
   "source": [
    "# 3. ƒê·ªãnh nghƒ©a c√°c m√¥ h√¨nh v√† Grid Search Parameters\n",
    "\n",
    "# Logistic Regression\n",
    "lr_params = {\n",
    "    'estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'estimator__solver': ['lbfgs', 'liblinear'],\n",
    "    'estimator__max_iter': [200, 500, 1000]\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [10, 20, 30, None],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "xgb_params = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [3, 5, 7, 10],\n",
    "    'estimator__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'estimator__subsample': [0.8, 1.0],\n",
    "    'estimator__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "models_config = {\n",
    "    'Logistic Regression': {\n",
    "        'model': MultiOutputClassifier(LogisticRegression(random_state=42)),\n",
    "        'params': lr_params\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': MultiOutputClassifier(RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
    "        'params': rf_params\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': MultiOutputClassifier(XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False)),\n",
    "        'params': xgb_params\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"C·∫•u h√¨nh m√¥ h√¨nh ƒë√£ s·∫µn s√†ng!\")\n",
    "print(f\"S·ªë m√¥ h√¨nh: {len(models_config)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Ph√¢n t√≠ch ph√¢n ph·ªëi labels (ƒë·ªÉ hi·ªÉu v·∫•n ƒë·ªÅ CV score)\n",
    "\n",
    "print(\"=== Ph√¢n t√≠ch ph√¢n ph·ªëi Labels ===\\n\")\n",
    "\n",
    "print(\"Train set:\")\n",
    "for i, label in enumerate(label_cols):\n",
    "    unique, counts = np.unique(y_train[:, i], return_counts=True)\n",
    "    print(f\"  {label}:\")\n",
    "    for val, count in zip(unique, counts):\n",
    "        print(f\"    Class {val} ({'Correct' if val == 0 else 'Error'}): {count} ({count/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "for i, label in enumerate(label_cols):\n",
    "    unique, counts = np.unique(y_test[:, i], return_counts=True)\n",
    "    print(f\"  {label}:\")\n",
    "    for val, count in zip(unique, counts):\n",
    "        print(f\"    Class {val} ({'Correct' if val == 0 else 'Error'}): {count} ({count/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, label in enumerate(label_cols):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    train_counts = np.bincount(y_train[:, i].astype(int), minlength=2)\n",
    "    test_counts = np.bincount(y_test[:, i].astype(int), minlength=2)\n",
    "    \n",
    "    x = np.arange(2)\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, train_counts, width, label='Train', alpha=0.8)\n",
    "    ax.bar(x + width/2, test_counts, width, label='Test', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{label}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Correct', 'Error'])\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Th√™m gi√° tr·ªã\n",
    "    for j, (train_c, test_c) in enumerate(zip(train_counts, test_counts)):\n",
    "        ax.text(j - width/2, train_c, str(train_c), ha='center', va='bottom', fontsize=9)\n",
    "        ax.text(j + width/2, test_c, str(test_c), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  L∆∞u √Ω: N·∫øu m·ªôt label c√≥ qu√° √≠t samples c·ªßa 1 class (< 5%), c√≥ th·ªÉ g√¢y ra:\")\n",
    "print(\"   - CV Score = NaN (kh√¥ng ƒë·ªß samples trong 1 fold)\")\n",
    "print(\"   - F1-Score th·∫•p ho·∫∑c NaN\")\n",
    "print(\"   - Model kh√¥ng h·ªçc ƒë∆∞·ª£c class hi·∫øm\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ƒêang train: Logistic Regression\n",
      "============================================================\n",
      "\n",
      "B·∫Øt ƒë·∫ßu GridSearchCV cho Logistic Regression...\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "\n",
      "‚ùå L·ªói khi train Logistic Regression: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)\n",
      "\n",
      "============================================================\n",
      "ƒêang train: Random Forest\n",
      "============================================================\n",
      "\n",
      "B·∫Øt ƒë·∫ßu GridSearchCV cho Random Forest...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "\n",
      "‚ùå L·ªói khi train Logistic Regression: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)\n",
      "\n",
      "============================================================\n",
      "ƒêang train: Random Forest\n",
      "============================================================\n",
      "\n",
      "B·∫Øt ƒë·∫ßu GridSearchCV cho Random Forest...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "\n",
      "Random Forest - K·∫øt qu·∫£:\n",
      "  Best CV Score: 0.8911\n",
      "  Test Accuracy: 0.7690\n",
      "  Test F1 (weighted): 0.9150\n",
      "  Test F1 (macro): 0.2786\n",
      "  Test Hamming Loss: 0.0770\n",
      "  Best Params: {'estimator__max_depth': 20, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 50}\n",
      "\n",
      "============================================================\n",
      "ƒêang train: XGBoost\n",
      "============================================================\n",
      "\n",
      "B·∫Øt ƒë·∫ßu GridSearchCV cho XGBoost...\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Random Forest - K·∫øt qu·∫£:\n",
      "  Best CV Score: 0.8911\n",
      "  Test Accuracy: 0.7690\n",
      "  Test F1 (weighted): 0.9150\n",
      "  Test F1 (macro): 0.2786\n",
      "  Test Hamming Loss: 0.0770\n",
      "  Best Params: {'estimator__max_depth': 20, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 50}\n",
      "\n",
      "============================================================\n",
      "ƒêang train: XGBoost\n",
      "============================================================\n",
      "\n",
      "B·∫Øt ƒë·∫ßu GridSearchCV cho XGBoost...\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "‚ùå L·ªói khi train XGBoost: [17:22:54] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\objective\\regression_obj.cu:119: Check failed: is_valid: base_score must be in (0,1) for the logistic loss.\n",
      "\n",
      "============================================================\n",
      "Ho√†n th√†nh vi·ªác hu·∫•n luy·ªán t·∫•t c·∫£ c√°c m√¥ h√¨nh!\n",
      "============================================================\n",
      "\n",
      "‚ùå L·ªói khi train XGBoost: [17:22:54] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\objective\\regression_obj.cu:119: Check failed: is_valid: base_score must be in (0,1) for the logistic loss.\n",
      "\n",
      "============================================================\n",
      "Ho√†n th√†nh vi·ªác hu·∫•n luy·ªán t·∫•t c·∫£ c√°c m√¥ h√¨nh!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. Hu·∫•n luy·ªán v√† t·ªëi ∆∞u h√≥a c√°c m√¥ h√¨nh b·∫±ng GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer, hamming_loss\n",
    "\n",
    "# Custom scorer cho multi-label classification\n",
    "def multi_label_f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    T√≠nh F1-score trung b√¨nh cho multi-label classification\n",
    "    X·ª≠ l√Ω tr∆∞·ªùng h·ª£p c√≥ label ch·ªâ c√≥ 1 class\n",
    "    \"\"\"\n",
    "    f1_scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        # Ki·ªÉm tra n·∫øu ch·ªâ c√≥ 1 class trong y_true\n",
    "        if len(np.unique(y_true[:, i])) == 1:\n",
    "            # N·∫øu d·ª± ƒëo√°n ƒë√∫ng 100% th√¨ f1=1, sai th√¨ f1=0\n",
    "            if np.array_equal(y_true[:, i], y_pred[:, i]):\n",
    "                f1_scores.append(1.0)\n",
    "            else:\n",
    "                f1_scores.append(0.0)\n",
    "        else:\n",
    "            # T√≠nh F1 b√¨nh th∆∞·ªùng\n",
    "            f1 = f1_score(y_true[:, i], y_pred[:, i], average='weighted', zero_division=0)\n",
    "            f1_scores.append(f1)\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# T·∫°o custom scorer\n",
    "custom_scorer = make_scorer(multi_label_f1_score, greater_is_better=True)\n",
    "\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for model_name, config in models_config.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ƒêang train: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Kh·ªüi t·∫°o GridSearchCV v·ªõi custom scorer\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        cv=5,  # TƒÉng l√™n 5-fold ƒë·ªÉ c√≥ nhi·ªÅu d·ªØ li·ªáu h∆°n m·ªói fold\n",
    "        scoring=custom_scorer,  # D√πng custom scorer\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        return_train_score=True,\n",
    "        error_score=0.0  # N·∫øu c√≥ l·ªói th√¨ cho score = 0 thay v√¨ raise\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    print(f\"\\nB·∫Øt ƒë·∫ßu GridSearchCV cho {model_name}...\")\n",
    "    try:\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Ki·ªÉm tra n·∫øu best_score_ l√† NaN\n",
    "        if np.isnan(grid_search.best_score_):\n",
    "            print(f\"\\n‚ö†Ô∏è  WARNING: CV Score l√† NaN cho {model_name}\")\n",
    "            print(\"   C√≥ th·ªÉ do d·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng ho·∫∑c qu√° √≠t samples\")\n",
    "            # Ti·∫øp t·ª•c nh∆∞ng l∆∞u √Ω\n",
    "        \n",
    "        # L∆∞u best model\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        \n",
    "        # D·ª± ƒëo√°n tr√™n t·∫≠p test\n",
    "        y_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "        \n",
    "        # T√≠nh to√°n metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # T√≠nh F1-score cho t·ª´ng label r·ªìi l·∫•y trung b√¨nh\n",
    "        f1_per_label = []\n",
    "        for i in range(y_test.shape[1]):\n",
    "            # Ki·ªÉm tra s·ªë l∆∞·ª£ng classes\n",
    "            unique_classes = len(np.unique(y_test[:, i]))\n",
    "            if unique_classes == 1:\n",
    "                # Ch·ªâ c√≥ 1 class\n",
    "                if np.array_equal(y_test[:, i], y_pred[:, i]):\n",
    "                    f1_per_label.append(1.0)\n",
    "                else:\n",
    "                    f1_per_label.append(0.0)\n",
    "            else:\n",
    "                f1 = f1_score(y_test[:, i], y_pred[:, i], average='weighted', zero_division=0)\n",
    "                f1_per_label.append(f1)\n",
    "        \n",
    "        f1_weighted = np.mean(f1_per_label)\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "        \n",
    "        # Hamming Loss (t·ª∑ l·ªá labels b·ªã d·ª± ƒëo√°n sai)\n",
    "        h_loss = hamming_loss(y_test, y_pred)\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£\n",
    "        results[model_name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_cv_score': grid_search.best_score_,\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_f1_weighted': f1_weighted,\n",
    "            'test_f1_macro': f1_macro,\n",
    "            'test_f1_micro': f1_micro,\n",
    "            'test_hamming_loss': h_loss,\n",
    "            'y_pred': y_pred,\n",
    "            'f1_per_label': f1_per_label  # L∆∞u F1 cho t·ª´ng label\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{model_name} - K·∫øt qu·∫£:\")\n",
    "        print(f\"  Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"  Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Test F1 (weighted): {f1_weighted:.4f}\")\n",
    "        print(f\"  Test F1 (macro): {f1_macro:.4f}\")\n",
    "        print(f\"  Test Hamming Loss: {h_loss:.4f}\")\n",
    "        print(f\"  F1 per label: {[f'{f:.4f}' for f in f1_per_label]}\")\n",
    "        print(f\"  Best Params: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå L·ªói khi train {model_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Ho√†n th√†nh vi·ªác hu·∫•n luy·ªán t·∫•t c·∫£ c√°c m√¥ h√¨nh!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== So s√°nh c√°c m√¥ h√¨nh ===\n",
      "        Model  CV Score  Test Accuracy  Test F1 (weighted)  Test F1 (macro)  Test F1 (micro)\n",
      "Random Forest  0.891105       0.769006            0.915009         0.278594         0.798469\n",
      "\n",
      "‚úì ƒê√£ l∆∞u b·∫£ng so s√°nh v√†o 'output/bicep_curl_models_comparison.csv'\n",
      "\n",
      "üèÜ M√¥ h√¨nh t·ªët nh·∫•t: Random Forest\n",
      "   F1-Score (weighted): 0.9150\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì so s√°nh v√†o 'output/bicep_curl_models_comparison.png'\n"
     ]
    }
   ],
   "source": [
    "# 5. So s√°nh v√† l·ª±a ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t\n",
    "\n",
    "# T·∫°o DataFrame ƒë·ªÉ so s√°nh\n",
    "comparison_data = []\n",
    "for model_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'CV Score': result['best_cv_score'],\n",
    "        'Test Accuracy': result['test_accuracy'],\n",
    "        'Test F1 (weighted)': result['test_f1_weighted'],\n",
    "        'Test F1 (macro)': result['test_f1_macro'],\n",
    "        'Test F1 (micro)': result['test_f1_micro']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test F1 (weighted)', ascending=False)\n",
    "print(\"\\n=== So s√°nh c√°c m√¥ h√¨nh ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# L∆∞u b·∫£ng so s√°nh\n",
    "comparison_df.to_csv('output/bicep_curl_models_comparison.csv', index=False)\n",
    "print(\"\\n‚úì ƒê√£ l∆∞u b·∫£ng so s√°nh v√†o 'output/bicep_curl_models_comparison.csv'\")\n",
    "\n",
    "# Ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"\\nüèÜ M√¥ h√¨nh t·ªët nh·∫•t: {best_model_name}\")\n",
    "print(f\"   F1-Score (weighted): {comparison_df.iloc[0]['Test F1 (weighted)']:.4f}\")\n",
    "\n",
    "# Visualization - So s√°nh c√°c metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['Test Accuracy', 'Test F1 (weighted)', 'Test F1 (macro)']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    bars = ax.bar(comparison_df['Model'], comparison_df[metric], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    ax.set_title(metric, fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Th√™m gi√° tr·ªã tr√™n c·ªôt\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/bicep_curl_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì so s√°nh v√†o 'output/bicep_curl_models_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ƒê√°nh gi√° chi ti·∫øt: Random Forest\n",
      "============================================================\n",
      "\n",
      "=== Classification Report cho t·ª´ng label ===\n",
      "\n",
      "\n",
      "Label: label_back\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Correct       0.76      0.85      0.80       291\n",
      "       Error       0.88      0.80      0.84       393\n",
      "\n",
      "    accuracy                           0.82       684\n",
      "   macro avg       0.82      0.82      0.82       684\n",
      "weighted avg       0.83      0.82      0.82       684\n",
      "\n",
      "\n",
      "Label: label_elbow\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Correct       0.95      1.00      0.97       649\n",
      "       Error       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.47      0.50      0.49       684\n",
      "weighted avg       0.90      0.95      0.92       684\n",
      "\n",
      "\n",
      "Label: label_flare\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_best\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCorrect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mError\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Confusion Matrix cho t·ª´ng label\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Confusion Matrix cho t·ª´ng label ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Learning\\Collage\\2026\\hocki1\\PBL 6\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32me:\\Learning\\Collage\\2026\\hocki1\\PBL 6\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2970\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2964\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2965\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2966\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2967\u001b[0m             )\n\u001b[0;32m   2968\u001b[0m         )\n\u001b[0;32m   2969\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2970\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2973\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2974\u001b[0m         )\n\u001b[0;32m   2975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2976\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# 6. ƒê√°nh gi√° chi ti·∫øt m√¥ h√¨nh t·ªët nh·∫•t\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ƒê√°nh gi√° chi ti·∫øt: {best_model_name}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "y_pred_best = results[best_model_name]['y_pred']\n",
    "\n",
    "# Classification Report cho t·ª´ng label\n",
    "print(\"=== Classification Report cho t·ª´ng label ===\\n\")\n",
    "for i, label in enumerate(label_cols):\n",
    "    print(f\"\\nLabel: {label}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Ki·ªÉm tra s·ªë l∆∞·ª£ng classes th·ª±c t·∫ø\n",
    "    unique_true = np.unique(y_test[:, i])\n",
    "    unique_pred = np.unique(y_pred_best[:, i])\n",
    "    unique_all = np.unique(np.concatenate([unique_true, unique_pred]))\n",
    "    \n",
    "    if len(unique_all) == 1:\n",
    "        # Ch·ªâ c√≥ 1 class duy nh·∫•t\n",
    "        print(f\"‚ö†Ô∏è  Ch·ªâ c√≥ 1 class trong test set: {'Correct' if unique_all[0] == 0 else 'Error'}\")\n",
    "        print(f\"   Accuracy: {accuracy_score(y_test[:, i], y_pred_best[:, i]):.4f}\")\n",
    "    else:\n",
    "        # C√≥ 2 classes - in report b√¨nh th∆∞·ªùng nh∆∞ng kh√¥ng ch·ªâ ƒë·ªãnh target_names\n",
    "        # ƒë·ªÉ sklearn t·ª± ƒë·ªông x·ª≠ l√Ω\n",
    "        print(classification_report(y_test[:, i], y_pred_best[:, i], \n",
    "                                    labels=[0, 1],\n",
    "                                    target_names=['Correct', 'Error'],\n",
    "                                    zero_division=0))\n",
    "\n",
    "# Confusion Matrix cho t·ª´ng label\n",
    "print(\"\\n\\n=== Confusion Matrix cho t·ª´ng label ===\")\n",
    "matrices = multilabel_confusion_matrix(y_test, y_pred_best)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (matrix, label) in enumerate(zip(matrices, label_cols)):\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Correct', 'Error'],\n",
    "                yticklabels=['Correct', 'Error'])\n",
    "    ax.set_title(f'{label}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/bicep_curl_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì ƒê√£ l∆∞u confusion matrices v√†o 'output/bicep_curl_confusion_matrices.png'\")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh t·ªët nh·∫•t\n",
    "joblib.dump(best_model, 'output/bicep_curl_best_model.joblib')\n",
    "joblib.dump(scaler, 'output/bicep_curl_scaler.joblib')\n",
    "print(f\"\\n‚úì ƒê√£ l∆∞u m√¥ h√¨nh t·ªët nh·∫•t v√†o 'output/bicep_curl_best_model.joblib'\")\n",
    "print(f\"‚úì ƒê√£ l∆∞u scaler v√†o 'output/bicep_curl_scaler.joblib'\")\n",
    "\n",
    "# L∆∞u th√¥ng tin m√¥ h√¨nh\n",
    "with open('output/bicep_curl_model_info.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"Best Model: {best_model_name}\\n\")\n",
    "    f.write(f\"Best Parameters: {results[best_model_name]['best_params']}\\n\\n\")\n",
    "    f.write(f\"Performance Metrics:\\n\")\n",
    "    f.write(f\"  - CV Score: {results[best_model_name]['best_cv_score']:.4f}\\n\")\n",
    "    f.write(f\"  - Test Accuracy: {results[best_model_name]['test_accuracy']:.4f}\\n\")\n",
    "    f.write(f\"  - Test F1 (weighted): {results[best_model_name]['test_f1_weighted']:.4f}\\n\")\n",
    "    f.write(f\"  - Test F1 (macro): {results[best_model_name]['test_f1_macro']:.4f}\\n\")\n",
    "    f.write(f\"  - Test F1 (micro): {results[best_model_name]['test_f1_micro']:.4f}\\n\")\n",
    "    f.write(f\"  - Test Hamming Loss: {results[best_model_name]['test_hamming_loss']:.4f}\\n\\n\")\n",
    "    f.write(f\"Feature Columns: {len(feature_cols)} features\\n\")\n",
    "    f.write(f\"Label Columns: {label_cols}\\n\")\n",
    "    f.write(f\"Training samples: {len(X_train_scaled)}\\n\")\n",
    "    f.write(f\"Test samples: {len(X_test_scaled)}\\n\")\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u th√¥ng tin m√¥ h√¨nh v√†o 'output/bicep_curl_model_info.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Inference - D·ª± ƒëo√°n tr√™n video (Per-frame prediction)\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Kh·ªüi t·∫°o MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_landmarks_from_frame(results):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t 132 features t·ª´ 1 frame (33 landmarks x 4 gi√° tr·ªã)\n",
    "    \"\"\"\n",
    "    if not results.pose_landmarks:\n",
    "        return np.zeros(132)  # Tr·∫£ v·ªÅ vector 0 n·∫øu kh√¥ng ph√°t hi·ªán pose\n",
    "        \n",
    "    row = []\n",
    "    for landmark in results.pose_landmarks.landmark:\n",
    "        row.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "    return np.array(row)\n",
    "\n",
    "def predict_video_per_frame(video_path, model, scaler, threshold=0.5, output_path='output_demo.mp4'):\n",
    "    \"\"\"\n",
    "    D·ª± ƒëo√°n t·ª´ng frame ri√™ng l·∫ª (kh√¥ng c·∫ßn chu·ªói/sequence)\n",
    "    \n",
    "    Args:\n",
    "        video_path: ƒê∆∞·ªùng d·∫´n video ƒë·∫ßu v√†o\n",
    "        model: M√¥ h√¨nh ƒë√£ train\n",
    "        scaler: StandardScaler ƒë√£ fit\n",
    "        threshold: Ng∆∞·ª°ng x√°c su·∫•t ƒë·ªÉ coi l√† l·ªói (0-1)\n",
    "        output_path: ƒê∆∞·ªùng d·∫´n video ƒë·∫ßu ra\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Setup output video\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    label_names = ['Back Error', 'Elbow Error', 'Flare Error']\n",
    "    frame_count = 0\n",
    "    \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # MediaPipe x·ª≠ l√Ω\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = pose.process(image)\n",
    "            \n",
    "            # V·∫Ω skeleton l√™n frame\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            # D·ª± ƒëo√°n cho frame hi·ªán t·∫°i\n",
    "            current_errors = []\n",
    "            if results.pose_landmarks:\n",
    "                # Tr√≠ch xu·∫•t features\n",
    "                landmarks = extract_landmarks_from_frame(results)\n",
    "                \n",
    "                # Chu·∫©n h√≥a\n",
    "                landmarks_scaled = scaler.transform(landmarks.reshape(1, -1))\n",
    "                \n",
    "                # D·ª± ƒëo√°n\n",
    "                prediction = model.predict_proba(landmarks_scaled)\n",
    "                \n",
    "                # X·ª≠ l√Ω k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "                # prediction l√† list of arrays (1 array cho m·ªói label)\n",
    "                for idx, label_name in enumerate(label_names):\n",
    "                    # L·∫•y x√°c su·∫•t c·ªßa class 1 (Error)\n",
    "                    prob_error = prediction[idx][0][1] if len(prediction[idx][0]) > 1 else prediction[idx][0][0]\n",
    "                    \n",
    "                    if prob_error > threshold:\n",
    "                        current_errors.append(f\"{label_name} ({prob_error:.2f})\")\n",
    "            \n",
    "            # V·∫Ω th√¥ng tin l√™n frame\n",
    "            # T·∫°o n·ªÅn cho text\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (400, 100 + len(current_errors)*40), (0, 0, 0), -1)\n",
    "            cv2.addWeighted(overlay, 0.6, image, 0.4, 0, image)\n",
    "            \n",
    "            # Ti√™u ƒë·ªÅ\n",
    "            cv2.putText(image, \"AI TRAINER - Per Frame\", (15, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Hi·ªÉn th·ªã tr·∫°ng th√°i\n",
    "            if not current_errors:\n",
    "                cv2.putText(image, \"Status: CORRECT FORM\", (15, 70), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(image, \"Status: ERRORS DETECTED\", (15, 70), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Hi·ªÉn th·ªã c√°c l·ªói\n",
    "                y_pos = 110\n",
    "                for err in current_errors:\n",
    "                    cv2.putText(image, f\"  - {err}\", (15, y_pos), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "                    y_pos += 35\n",
    "            \n",
    "            # Frame counter\n",
    "            cv2.putText(image, f\"Frame: {frame_count}\", (width - 150, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            \n",
    "            out.write(image)\n",
    "            \n",
    "            # Uncomment ƒë·ªÉ xem real-time (kh√¥ng ho·∫°t ƒë·ªông tr√™n Jupyter)\n",
    "            # cv2.imshow('AI Trainer', image)\n",
    "            # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            #     break\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"‚úì ƒê√£ x·ª≠ l√Ω {frame_count} frames\")\n",
    "    print(f\"‚úì Video ƒë·∫ßu ra: {output_path}\")\n",
    "\n",
    "# --- CH·∫†Y DEMO ---\n",
    "# Load model v√† scaler\n",
    "loaded_model = joblib.load('output/bicep_curl_best_model.joblib')\n",
    "loaded_scaler = joblib.load('output/bicep_curl_scaler.joblib')\n",
    "\n",
    "# Ch·∫°y prediction\n",
    "video_path = '../data/biceps curl/4d69dc08-6123-4a2c-98df-3dddf71e6d79.mp4'\n",
    "predict_video_per_frame(video_path, loaded_model, loaded_scaler, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìã T√≥m t·∫Øt Pipeline\n",
    "\n",
    "## üîÑ Thay ƒë·ªïi ch√≠nh:\n",
    "\n",
    "### **Tr∆∞·ªõc (LSTM):**\n",
    "- X·ª≠ l√Ω **chu·ªói frames** (sequences) v·ªõi window size = 30\n",
    "- Model: LSTM layers\n",
    "- Input shape: (batch, 30, 132)\n",
    "\n",
    "### **Sau (ML Classification):**\n",
    "- X·ª≠ l√Ω **t·ª´ng frame ri√™ng l·∫ª** (per-frame)\n",
    "- Models: \n",
    "  - ‚úÖ Logistic Regression\n",
    "  - ‚úÖ Random Forest\n",
    "  - ‚úÖ XGBoost\n",
    "- Input shape: (batch, 132)\n",
    "- **T·ªëi ∆∞u h√≥a si√™u tham s·ªë** b·∫±ng GridSearchCV\n",
    "\n",
    "## üìä Pipeline m·ªõi:\n",
    "\n",
    "1. **Load Data**: ƒê·ªçc file CSV v·ªõi landmarks v√† labels\n",
    "2. **Feature Engineering**: Tr√≠ch xu·∫•t 132 features (33 landmarks √ó 4 gi√° tr·ªã)\n",
    "3. **Data Splitting**: Chia train/test theo video_id (tr√°nh data leakage)\n",
    "4. **Scaling**: StandardScaler cho features\n",
    "5. **Model Training**: \n",
    "   - Train 3 models v·ªõi GridSearchCV\n",
    "   - Cross-validation 3-fold\n",
    "   - T·ªëi ∆∞u hyperparameters\n",
    "6. **Model Comparison**: So s√°nh performance v√† ch·ªçn model t·ªët nh·∫•t\n",
    "7. **Evaluation**: Classification report, confusion matrix\n",
    "8. **Save Models**: L∆∞u best model v√† scaler\n",
    "9. **Inference**: D·ª± ƒëo√°n real-time tr√™n video (per-frame)\n",
    "\n",
    "## üíæ Output Files:\n",
    "\n",
    "- `bicep_curl_best_model.joblib` - Model t·ªët nh·∫•t\n",
    "- `bicep_curl_scaler.joblib` - StandardScaler\n",
    "- `bicep_curl_models_comparison.csv` - B·∫£ng so s√°nh models\n",
    "- `bicep_curl_model_info.txt` - Th√¥ng tin chi ti·∫øt model\n",
    "- `bicep_curl_confusion_matrices.png` - Confusion matrices visualization\n",
    "- `bicep_curl_models_comparison.png` - Bi·ªÉu ƒë·ªì so s√°nh performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
